// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package models

import (
	"regexp"
	"slices"
	"strings"

	"github.com/ossf/osv-schema/bindings/go/osvschema"
)

var nonAlphanumericRegex = regexp.MustCompile(`[^a-zA-Z0-9]+`)

func tokenize(value string) []string {
	valueLower := strings.ToLower(value)
	tokens := make(map[string]struct{})

	// Split by non-alphanumeric characters.
	for _, token := range nonAlphanumericRegex.Split(valueLower, -1) {
		if token != "" {
			tokens[token] = struct{}{}
		}
	}
	tokens[valueLower] = struct{}{}

	// Add subsection combinations from ID (split at '-').
	parts := strings.Split(valueLower, "-")
	numParts := len(parts)
	for length := 2; length <= numParts; length++ {
		for i := 0; i <= numParts-length; i++ {
			subParts := parts[i : i+length]
			combo := strings.Join(subParts, "-")
			tokens[combo] = struct{}{}
		}
	}

	result := make([]string, 0, len(tokens))
	for token := range tokens {
		result = append(result, token)
	}
	slices.Sort(result)
	return result
}

var ubuntuReplacer = strings.NewReplacer(":Pro", "", ":LTS", "")

func removeVariants(ecosystem string) string {
	// For Ubuntu, remove ":Pro" and ":LTS"
	if strings.HasPrefix(ecosystem, "Ubuntu") {
		return ubuntuReplacer.Replace(ecosystem)
	}
	return ""
}

func NewListedVulnerabilityFromProto(vuln *osvschema.Vulnerability) *ListedVulnerability {
	published := vuln.Published.AsTime()
	summary := vuln.Summary

	allEcosystems := make(map[string]struct{})
	allPackages := make(map[string]struct{})
	isFixed := false
	severities := make(map[[2]string]struct{})

	for _, sev := range vuln.Severity {
		severities[[2]string{sev.Type.String(), sev.Score}] = struct{}{}
	}

	searchIndices := make(map[string]struct{})
	for _, t := range tokenize(vuln.Id) {
		searchIndices[t] = struct{}{}
	}
	autocompleteTags := make(map[string]struct{})
	autocompleteTags[strings.ToLower(vuln.Id)] = struct{}{}

	for _, alias := range vuln.Aliases {
		for _, t := range tokenize(alias) {
			searchIndices[t] = struct{}{}
		}
	}
	for _, upstream := range vuln.Upstream {
		for _, t := range tokenize(upstream) {
			searchIndices[t] = struct{}{}
		}
	}

	for _, affected := range vuln.Affected {
		if affected.Package.Name != "" {
			for _, t := range tokenize(affected.Package.Name) {
				searchIndices[t] = struct{}{}
			}
			autocompleteTags[strings.ToLower(affected.Package.Name)] = struct{}{}
			allPackages[affected.Package.Ecosystem+"/"+affected.Package.Name] = struct{}{}
		}
		if affected.Package.Ecosystem != "" {
			allEcosystems[affected.Package.Ecosystem] = struct{}{}
		}
		for _, sev := range affected.Severity {
			severities[[2]string{sev.Type.String(), sev.Score}] = struct{}{}
		}
		for _, r := range affected.Ranges {
			if r.Type == osvschema.Range_GIT {
				allEcosystems["GIT"] = struct{}{}
				searchIndices[r.Repo] = struct{}{}
				autocompleteTags[strings.ToLower(r.Repo)] = struct{}{}

				split := strings.Split(r.Repo, "//")
				if len(split) >= 2 {
					noHTTP := split[1]
					allPackages[noHTTP] = struct{}{}
					searchIndices[noHTTP] = struct{}{}
					// Add the path components excluding the domain name
					pathParts := strings.Split(noHTTP, "/")
					if len(pathParts) > 1 {
						for _, part := range pathParts[1:] {
							searchIndices[part] = struct{}{}
						}
					}
				} else {
					allPackages[r.Repo] = struct{}{}
				}
			}
			for _, e := range r.Events {
				if e.GetFixed() != "" || e.GetLimit() != "" {
					isFixed = true
				}
			}
		}
	}

	for eco := range allEcosystems {
		for _, t := range tokenize(eco) {
			searchIndices[t] = struct{}{}
		}
		if v := removeVariants(eco); v != "" {
			for _, t := range tokenize(v) {
				searchIndices[t] = struct{}{}
			}
		}
	}

	ecosystems := make([]string, 0, len(allEcosystems))
	for eco := range allEcosystems {
		ecosystems = append(ecosystems, eco)
	}
	slices.Sort(ecosystems)

	packages := make([]string, 0, len(allPackages))
	for pkg := range allPackages {
		packages = append(packages, pkg)
	}
	slices.Sort(packages)

	sevList := make([]Severity, 0, len(severities))
	for sev := range severities {
		sevList = append(sevList, Severity{Type: sev[0], Score: sev[1]})
	}
	// Sort for determinism.
	slices.SortFunc(sevList, func(a, b Severity) int {
		if n := strings.Compare(a.Type, b.Type); n != 0 {
			return n
		}
		return strings.Compare(a.Score, b.Score)
	})

	searchIndicesList := make([]string, 0, len(searchIndices))
	for si := range searchIndices {
		searchIndicesList = append(searchIndicesList, si)
	}
	slices.Sort(searchIndicesList)

	autocompleteTagsList := make([]string, 0, len(autocompleteTags))
	for tag := range autocompleteTags {
		autocompleteTagsList = append(autocompleteTagsList, tag)
	}
	slices.Sort(autocompleteTagsList)

	return &ListedVulnerability{
		Published:        published,
		Ecosystems:       ecosystems,
		Packages:         packages,
		Summary:          summary,
		IsFixed:          isFixed,
		Severities:       sevList,
		AutocompleteTags: autocompleteTagsList,
		SearchIndices:    searchIndicesList,
	}
}
